{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Copyright 2020 Google LLC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_K3eRbcw_SRI"
   },
   "source": [
    "# Visualize the MetaLearning pipeline built on top NitroML. \n",
    "# We are using NitroML on Kubeflow: \n",
    "\n",
    "This notebook allows users to analyze NitroML metalearning pipelines results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Configure your cluster with gcloud\n",
    "# `gcloud container clusters get-credentials <cluster_name> --zone <cluster-zone> --project <project-id>\n",
    "\n",
    "# Step 2: Get the port where the gRPC service is running on the cluster\n",
    "# `kubectl get configmap metadata-grpc-configmap -o jsonpath={.data}`\n",
    "# Use `METADATA_GRPC_SERVICE_PORT` in the next step. The default port used is 8080.\n",
    "\n",
    "# Step 3: Port forwarding\n",
    "# `kubectl port-forward deployment/metadata-grpc-deployment 9898:<METADATA_GRPC_SERVICE_PORT>`\n",
    "\n",
    "# Troubleshooting\n",
    "# If getting error related to Metadata (For examples, Transaction already open). Try restarting the metadata-grpc-service using:\n",
    "# `kubectl rollout restart deployment metadata-grpc-deployment`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "PROJECT_DIR=os.path.join(sys.path[0], '..')\n",
    "%cd {PROJECT_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "colab": {},
    "colab_type": "code",
    "id": "gZQAacaeCfBh"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from examples import config as cloud_config\n",
    "import examples.tuner_data_utils as tuner_utils\n",
    "from ml_metadata.proto import metadata_store_pb2\n",
    "from ml_metadata.metadata_store import metadata_store\n",
    "from nitroml.benchmark import results\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import qgrid\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0vnwDmsobYGD"
   },
   "source": [
    "## Connect to the ML Metadata (MLMD) database\n",
    "\n",
    "First we need to connect to our MLMD database which stores the results of our\n",
    "benchmark runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_config = metadata_store_pb2.MetadataStoreClientConfig()\n",
    "\n",
    "connection_config.host = 'localhost'\n",
    "connection_config.port = 9898\n",
    "\n",
    "store = metadata_store.MetadataStore(connection_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get trial summary data (used to plot Area under Learning Curve) stored as AugmentedTuner artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name of the dataset/subbenchmark\n",
    "# This is used to filter out the component path.\n",
    "testdata = 'ilpd' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metalearning_data(meta_algorithm: str = '', test_dataset: str = '', multiple_runs: bool = True):\n",
    "    \n",
    "    d_list = []\n",
    "    execs = store.get_executions_by_type('nitroml.automl.metalearning.tuner.component.AugmentedTuner')\n",
    "    model_dir_map = {}\n",
    "    for tuner_exec in execs:\n",
    "\n",
    "        run_id = tuner_exec.properties['run_id'].string_value\n",
    "        pipeline_root = tuner_exec.properties['pipeline_root'].string_value\n",
    "        component_id = tuner_exec.properties['component_id'].string_value\n",
    "        pipeline_name = tuner_exec.properties['pipeline_name'].string_value\n",
    "        \n",
    "        if multiple_runs:\n",
    "            if '.run_' not in component_id:\n",
    "                continue\n",
    "                \n",
    "        if test_dataset not in component_id:\n",
    "            continue\n",
    "            \n",
    "        if f'metalearning_benchmark' != pipeline_name and meta_algorithm not in pipeline_name:\n",
    "            continue\n",
    "\n",
    "        config_path = os.path.join(pipeline_root, component_id, 'trial_summary_plot', str(tuner_exec.id))\n",
    "        model_dir_map[tuner_exec.id] = config_path\n",
    "        d_list.append(config_path)\n",
    "        \n",
    "    return d_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to tuner_dir from above\n",
    "# You can get the list of tuner_dirs by calling: get_metalearning_data(multiple_runs=False)\n",
    "example_plot = ''\n",
    "if not example_plot:\n",
    "    raise ValueError('Please specify the path to the tuner plot dir.')\n",
    "    \n",
    "with tf.io.gfile.GFile(os.path.join(example_plot, 'tuner_plot_data.txt'), mode='r') as fin:\n",
    "    data = json.load(fin)\n",
    "    \n",
    "tuner_utils.display_tuner_data(data, save_plot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Majority Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm = 'majority_voting' \n",
    "d_list = get_metalearning_data(algorithm, testdata)\n",
    "\n",
    "d_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the runs from `d_list` to visualize. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []\n",
    "\n",
    "for d in d_list:\n",
    "    with tf.io.gfile.GFile(os.path.join(d, 'tuner_plot_data.txt'), mode='r') as fin:\n",
    "        data_list.append(json.load(fin))\n",
    "\n",
    "tuner_utils.display_tuner_data_with_error_bars(data_list, save_plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm = 'nearest_neighbor' \n",
    "d_list = get_metalearning_data(algorithm, testdata)\n",
    "\n",
    "d_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the runs from `d_list` to visualize. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []\n",
    "\n",
    "for d in d_list:\n",
    "    with tf.io.gfile.GFile(os.path.join(d, 'tuner_plot_data.txt'), mode='r') as fin:\n",
    "        data_list.append(json.load(fin))\n",
    "\n",
    "tuner_utils.display_tuner_data_with_error_bars(data_list, save_plot=True)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "last_runtime": {
    "build_target": "",
    "kind": "local"
   },
   "name": "NitroML: Benchmark Overview",
   "provenance": [
    {
     "file_id": "/piper/depot/google3/third_party/py/nitroml/notebooks/overview.ipynb",
     "timestamp": 1586208407782
    },
    {
     "file_id": "/piper/depot/google3/third_party/py/nitroml/notebooks/overview.ipynb?workspaceId=weill:fig-export-nitroml-change-46-553046179877::citc",
     "timestamp": 1585765690231
    },
    {
     "file_id": "/piper/depot/google3/third_party/py/nitroml/notebooks/overview.ipynb",
     "timestamp": 1582049042220
    },
    {
     "file_id": "/piper/depot/google3/third_party/py/nitroml/notebooks/overview.ipynb",
     "timestamp": 1581544369324
    },
    {
     "file_id": "/piper/depot/google3/third_party/py/nitroml/notebooks/overview.ipynb",
     "timestamp": 1581018369993
    },
    {
     "file_id": "/v2/notebooks/charts.ipynb",
     "timestamp": 1579279346196
    }
   ],
   "toc_visible": true
  },
  "environment": {
   "name": "tf2-gpu.2-1.m48",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m48"
  },
  "finalized": {
   "timestamp": 1594386744738,
   "trusted": false
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "require": {
   "paths": {
    "buttons.colvis": "https://cdn.datatables.net/buttons/1.5.6/js/buttons.colVis.min",
    "buttons.flash": "https://cdn.datatables.net/buttons/1.5.6/js/buttons.flash.min",
    "buttons.html5": "https://cdn.datatables.net/buttons/1.5.6/js/buttons.html5.min",
    "buttons.print": "https://cdn.datatables.net/buttons/1.5.6/js/buttons.print.min",
    "chartjs": "https://cdnjs.cloudflare.com/ajax/libs/Chart.js/2.8.0/Chart",
    "d3": "https://d3js.org/d3.v5.min",
    "d3-array": "https://d3js.org/d3-array.v2.min",
    "datatables.net": "https://cdn.datatables.net/1.10.18/js/jquery.dataTables",
    "datatables.net-buttons": "https://cdn.datatables.net/buttons/1.5.6/js/dataTables.buttons.min",
    "datatables.responsive": "https://cdn.datatables.net/responsive/2.2.2/js/dataTables.responsive.min",
    "datatables.scroller": "https://cdn.datatables.net/scroller/2.0.0/js/dataTables.scroller.min",
    "datatables.select": "https://cdn.datatables.net/select/1.3.0/js/dataTables.select.min",
    "jszip": "https://cdnjs.cloudflare.com/ajax/libs/jszip/2.5.0/jszip.min",
    "moment": "https://cdnjs.cloudflare.com/ajax/libs/moment.js/2.8.0/moment",
    "pdfmake": "https://cdnjs.cloudflare.com/ajax/libs/pdfmake/0.1.36/pdfmake.min",
    "vfsfonts": "https://cdnjs.cloudflare.com/ajax/libs/pdfmake/0.1.36/vfs_fonts"
   },
   "shim": {
    "buttons.colvis": {
     "deps": [
      "jszip",
      "datatables.net-buttons"
     ]
    },
    "buttons.flash": {
     "deps": [
      "jszip",
      "datatables.net-buttons"
     ]
    },
    "buttons.html5": {
     "deps": [
      "jszip",
      "datatables.net-buttons"
     ]
    },
    "buttons.print": {
     "deps": [
      "jszip",
      "datatables.net-buttons"
     ]
    },
    "chartjs": {
     "deps": [
      "moment"
     ]
    },
    "datatables.net": {
     "exports": "$.fn.dataTable"
    },
    "datatables.net-buttons": {
     "deps": [
      "datatables.net"
     ]
    },
    "pdfmake": {
     "deps": [
      "datatables.net"
     ]
    },
    "vfsfonts": {
     "deps": [
      "datatables.net"
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
