{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Copyright 2020 Google LLC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo for NitroML on Cloud using KubeFlow "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Get `kfp` and `skaffold`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# install kfp (https://kubeflow-pipelines.readthedocs.io/en/latest/source/kfp.html)\n",
    "!{sys.executable} -m pip install --user --upgrade -q kfp==1.0.0\n",
    "!{sys.executable} -m pip install --user --upgrade -q kfp-server-api==1.0.0\n",
    "\n",
    "# Download skaffold and set it executable.\n",
    "# !curl -Lo skaffold https://storage.googleapis.com/skaffold/releases/latest/skaffold-linux-amd64 && chmod +x skaffold && mv skaffold /home/jupyter/.local/bin/\n",
    "    \n",
    "# Set `PATH` to include user python binary directory and a directory containing `skaffold`.\n",
    "PATH=%env PATH\n",
    "%env PATH={PATH}:/home/jupyter/.local/bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Check and install  tfx (if necessary)\n",
    "#### If TFX is not installed, uncomment the pip install command below. We have tested this example with `tfx==0.23.0.dev`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !{sys.executable} -m pip install --user --upgrade -q tensorflow_datasets==3.1.0\n",
    "!python3 -c \"import tfx; print('TFX version: {}'.format(tfx.__version__)); import tensorflow_datasets as tfds; print('TFDS version: {}'.format(tfds.__version__))\"\n",
    "!python3 -c \"import kfp; print('KFP version: {}'.format(kfp.__version__))\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Get the GCP project ID and create Docker image name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read GCP project id from env.\n",
    "shell_output=!gcloud config list --format 'value(core.project)' 2>/dev/null\n",
    "GCP_PROJECT_ID=shell_output[0]\n",
    "print(\"GCP project ID:\" + GCP_PROJECT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Docker image name for the pipeline image \n",
    "# IMAGE_NAME = 'nitroml_benchmark4'\n",
    "IMAGE_NAME = 'nitroml_tfx_0130.dev'\n",
    "CUSTOM_TFX_IMAGE='gcr.io/' + GCP_PROJECT_ID + '/' + IMAGE_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Set KFP Cluster End point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "PROJECT_DIR=os.path.join(sys.path[0], '..')\n",
    "%cd {PROJECT_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This refers to the KFP cluster endpoint\n",
    "# To find your endpoint, go to: Google_Project_Console -> AI_PLATFORMS -> PIPELINES. \n",
    "# Then for the cluster you want to run your pipeline on, click on the \"Open Pipeline Dashboard\". Copy the url \"*.googleusercontent.com\". This is your ENDPOINT var.\n",
    "\n",
    "from examples import config\n",
    "from absl import logging\n",
    "\n",
    "ENDPOINT = config.ENDPOINT\n",
    "logging.info(f'Using {ENDPOINT} as the ENDPOINT')\n",
    "\n",
    "if not ENDPOINT:\n",
    "    from absl import logging\n",
    "    logging.error('Set your ENDPOINT in this cell.')\n",
    "else:\n",
    "    logging.info(f'Using {ENDPOINT} as the ENDPOINT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPELINE_NAME=config.PIPELINE_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPELINE_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Create the tfx pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_OPENML_API_KEY = 'OPENML_API_KEY'\n",
    "\n",
    "os.environ[_OPENML_API_KEY] = 'b1514bb2761ecc4709ab26db50673a41'\n",
    "os.getenv(_OPENML_API_KEY, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = 'metalearning'\n",
    "example = 'openml_cc18'\n",
    "example = 'titanic'\n",
    "if example == 'titanic':\n",
    "    pipeline_path = 'examples/titanic_benchmark.py'\n",
    "    pipeline_name = f'{PIPELINE_NAME}_titanic'\n",
    "elif example == 'openml_cc18':\n",
    "    pipeline_path = 'examples/openml_cc18_benchmark.py'\n",
    "    pipeline_name = f'{PIPELINE_NAME}_openML_demo'\n",
    "elif example == 'metalearning':\n",
    "    algorithm = 'nearest_neighbor'\n",
    "#     algorithm = 'majority_voting'\n",
    "    pipeline_path = 'examples/metalearning_benchmark.py'\n",
    "    pipeline_name = f'metalearning_{algorithm}'\n",
    "\n",
    "TFX_IMAGE=config.TFX_IMAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['NITROML_RUNS_PER_BENCHMARK'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tfx pipeline create  \\\n",
    "--pipeline-path={pipeline_path} \\\n",
    "--endpoint={ENDPOINT} \\\n",
    "--build-target-image={CUSTOM_TFX_IMAGE} \\\n",
    "--build-base-image={TFX_IMAGE} \\\n",
    "--engine='kubeflow'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Run the created tfx pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7 (Optional): If the pipeline src is updated, we will have to update the pipeline at endpoint. The following block updates the pipeline and runs it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we update the pipeline\n",
    "!tfx pipeline update \\\n",
    "--pipeline-path={pipeline_path} \\\n",
    "--endpoint={ENDPOINT} \\\n",
    "--engine='kubeflow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (pipeline_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tfx run create --pipeline-name={pipeline_name}  --endpoint={ENDPOINT} --engine='kubeflow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !kfp --endpoint {ENDPOINT} --namespace kubeflow diagnose_me"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-1.m48",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m48"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
