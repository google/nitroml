{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Copyright 2020 Google LLC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We are using NitroML on Kubeflow: \n",
    "\n",
    "This notebook allows users to analyze NitroML benchmark results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook assumes you have followed the following steps to setup port-forwarding:\n",
    "\n",
    "# Step 1: Configure your cluster with gcloud\n",
    "# `gcloud container clusters get-credentials <cluster_name> --zone <cluster-zone> --project <project-id>\n",
    "\n",
    "# Step 2: Get the port where the gRPC service is running on the cluster\n",
    "# `kubectl get configmap metadata-grpc-configmap -o jsonpath={.data}`\n",
    "# Use `METADATA_GRPC_SERVICE_PORT` in the next step. The default port used is 8080.\n",
    "\n",
    "# Step 3: Port forwarding\n",
    "# `kubectl port-forward deployment/metadata-grpc-deployment 9898:<METADATA_GRPC_SERVICE_PORT>`\n",
    "\n",
    "# Troubleshooting\n",
    "# If getting error related to Metadata (For examples, Transaction already open). Try restarting the metadata-grpc-service using:\n",
    "# `kubectl rollout restart deployment metadata-grpc-deployment`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "PROJECT_DIR=os.path.join(sys.path[0], '..')\n",
    "%cd {PROJECT_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_metadata.proto import metadata_store_pb2\n",
    "from ml_metadata.metadata_store import metadata_store\n",
    "from nitroml.benchmark import results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to the ML Metadata (MLMD) database\n",
    "\n",
    "First we need to connect to our MLMD database which stores the results of our\n",
    "benchmark runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_config = metadata_store_pb2.MetadataStoreClientConfig()\n",
    "\n",
    "connection_config.host = 'localhost'\n",
    "connection_config.port = 9898\n",
    "\n",
    "store = metadata_store.MetadataStore(connection_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display benchmark results\n",
    "\n",
    "Next we load and visualize `pd.DataFrame` containing our benchmark results.\n",
    "These results contain contextual features such as the pipeline ID, and \n",
    "benchmark metrics as computed by the downstream Evaluators. If your\n",
    "benchmark included an `EstimatorTrainer` component, its hyperparameters may also\n",
    "display in the table below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@markdown ### Choose how to aggregate metrics:\n",
    "mean = False  #@param { type: \"boolean\" }\n",
    "stdev = False  #@param { type: \"boolean\" }\n",
    "min_and_max = False  #@param { type: \"boolean\" }\n",
    "\n",
    "agg = []\n",
    "if mean:\n",
    "    agg.append(\"mean\")\n",
    "if stdev:\n",
    "    agg.append(\"std\")\n",
    "if min_and_max:\n",
    "    agg += [\"min\", \"max\"]\n",
    "\n",
    "df = results.overview(store, metric_aggregators=agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can display an interactive table using qgrid\n",
    "\n",
    "Please follow the latest instructions on downloading qqgrid package from here: https://github.com/quantopian/qgrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import qgrid\n",
    "qgid_wdget = qgrid.show_grid(df, show_toolbar=True)\n",
    "qgid_wdget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-1.m48",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m48"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
